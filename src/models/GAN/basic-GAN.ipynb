{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/c/generative-dog-images/discussion/104281\n",
    "# https://machinelearningmastery.com/a-gentle-introduction-to-the-biggan/\n",
    "# https://machinelearningmastery.com/how-to-develop-a-conditional-generative-adversarial-network-from-scratch/\n",
    "# https://github.com/taki0112/BigGAN-Tensorflow/blob/master/BigGAN_128.py\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import cv2\n",
    "import glob\n",
    "import handshape_datasets as hd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from densenet import densenet_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import time\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, ZeroPadding2D, Dense, Dropout, Activation, Reshape, Flatten\n",
    "from tensorflow.keras.layers import AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D, BatchNormalization \n",
    "from tensorflow.keras.layers import Conv2DTranspose, LeakyReLU, Conv2D\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "WARNING:tensorflow:From <ipython-input-2-0dcb167e88d7>:14: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "              tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "        \n",
    "print(tf.config.experimental.list_logical_devices('GPU'))\n",
    "tf.test.is_gpu_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "# data\n",
    "rotation_range = 20\n",
    "width_shift_range = 0.2\n",
    "height_shift_range = 0.2\n",
    "horizontal_flip = True\n",
    "vertical_flip = False\n",
    "shear_range = 0\n",
    "zoom_range = 0.2\n",
    "\n",
    "# training\n",
    "g_lr = 0.001\n",
    "d_lr = 0.001\n",
    "epochs = 200\n",
    "max_patience = 200\n",
    "min_loss = 25\n",
    "min_loss_acc = 0\n",
    "batch_size = 128\n",
    "noise_dim = 256\n",
    "\n",
    "# log\n",
    "log_freq = 1\n",
    "models_directory = 'results/models/'\n",
    "date = datetime.now().strftime(\"%Y_%m_%d-%H:%M:%S\")\n",
    "identifier = \"simple_gan-\" + date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Loading rwth...\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'rwth'\n",
    "path = '/tf/data/{}'.format(dataset_name)\n",
    "data_dir = os.path.join(path, 'data')\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "    \n",
    "    \n",
    "data = hd.load(dataset_name, Path(data_dir))\n",
    "\n",
    "good_min = 40\n",
    "good_classes = []\n",
    "n_unique = len(np.unique(data[1]['y']))\n",
    "for i in range(n_unique):\n",
    "    images = data[0][np.equal(i, data[1]['y'])]\n",
    "    if len(images) >= good_min:\n",
    "        good_classes = good_classes + [i]\n",
    "\n",
    "x = data[0][np.in1d(data[1]['y'], good_classes)]\n",
    "img_shape = x[0].shape\n",
    "x = tf.image.resize(x, [int(img_shape[0]/2), int(img_shape[1]/2)]).numpy()\n",
    "img_shape = x[0].shape\n",
    "y = data[1]['y'][np.in1d(data[1]['y'], good_classes)]\n",
    "y_dict = dict(zip(np.unique(y), range(len(np.unique(y)))))\n",
    "y = np.vectorize(y_dict.get)(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, train_size=0.8, test_size=0.2, stratify=y)\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "n_classes = len(classes)\n",
    "train_size = x_train.shape[0]\n",
    "test_size = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 46, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=rotation_range,\n",
    "    width_shift_range=width_shift_range,\n",
    "    height_shift_range=height_shift_range,\n",
    "    horizontal_flip=horizontal_flip,\n",
    "    vertical_flip = vertical_flip,\n",
    "    shear_range=shear_range,\n",
    "    zoom_range=zoom_range,\n",
    "    fill_mode='constant',\n",
    "    cval=0,\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    ")\n",
    "\n",
    "test_datagen.fit(x_train)\n",
    "\n",
    "# create data generators\n",
    "train_gen =  datagen.flow(x_train, y_train, batch_size=batch_size)\n",
    "test_gen = test_datagen.flow(x_test, y_test , batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for images, _ in train_gen:\n",
    "    plt.imshow(images[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model(input_shape=(100,), output_shape=(66, 46, 3)):\n",
    "\n",
    "    noise_input = Input(shape=input_shape, name='noise_input')\n",
    "    \n",
    "    x = Dense(int(output_shape[0]/2)*int(output_shape[1]/2)*32, use_bias=False, input_shape=input_shape, name='dense1')(noise_input)\n",
    "    x = BatchNormalization(name='dense1_bn')(x)\n",
    "    x = LeakyReLU(name='dense1_leakyrelu')(x)\n",
    "\n",
    "    x = Reshape((int(output_shape[0]/2),int(output_shape[1]/2),32), name='reshape1')(x)\n",
    "\n",
    "    x = Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False, name='convt1')(x)\n",
    "    x = BatchNormalization(name='convt1_bn')(x)\n",
    "    x = LeakyReLU(name='convt1_leakyrelu')(x)\n",
    "\n",
    "    x = Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False, name='convt2')(x)\n",
    "    x = BatchNormalization(name='convt2_bn')(x)\n",
    "    x = LeakyReLU(name='convt2_leakyrelu')(x)\n",
    "\n",
    "    x = Conv2DTranspose(64, (5, 5), strides=(1, 1), padding='same', use_bias=False, name='convt3')(x)\n",
    "    x = BatchNormalization(name='convt3_bn')(x)\n",
    "    x = LeakyReLU(name='convt3_leakyrelu')(x)\n",
    "\n",
    "    output = Conv2DTranspose(output_shape[2], (5, 5), strides=(1, 1), padding='same', use_bias=False, activation='tanh', name='convt_out')(x)\n",
    "\n",
    "    return Model(inputs=noise_input, outputs=output)\n",
    "\n",
    "\n",
    "def discriminator_model(input_shape=(66, 46, 3)):\n",
    "    img_input = Input(shape=input_shape, name='img_input')\n",
    "    x = Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=input_shape, name='conv1')(img_input)\n",
    "    x = LeakyReLU(name='conv1_leakyrelu')(x)\n",
    "    x = Dropout(0.3, name='conv1_dropout')(x)\n",
    "\n",
    "    x = Conv2D(128, (5, 5), strides=(2, 2), padding='same', name='conv2')(x)\n",
    "    x = LeakyReLU(name='conv2_leakyrelu')(x)\n",
    "    x = Dropout(0.3, name='conv2_dropout')(x)\n",
    "\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    output = Dense(1, name='out_dense')(x)\n",
    "\n",
    "    return Model(inputs=img_input, outputs=output)\n",
    "\n",
    "generator = generator_model(input_shape=(noise_dim,), output_shape=img_shape)\n",
    "discriminator = discriminator_model(input_shape=img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses and optimizers\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(g_lr)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(d_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_loss = tf.keras.metrics.Mean(name='discriminator_loss')\n",
    "generator_loss = tf.keras.metrics.Mean(name='generator_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([images.shape[0], noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "        \n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "                \n",
    "        gen_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "        \n",
    "        real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "        fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "        disc_loss = real_loss + fake_loss\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    discriminator_loss(gen_loss)\n",
    "    generator_loss(disc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create summary writers\n",
    "train_summary_writer = tf.summary.create_file_writer('results/summaries/train/' + identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "Epoch: 0, Generator Loss: 0.6408173441886902, Discriminator Loss: 3.4223251342773438, Time: 6.692447900772095 s\n",
      "Epoch: 1, Generator Loss: 5.663194179534912, Discriminator Loss: 11.904892921447754, Time: 2.009120225906372 s\n",
      "Epoch: 2, Generator Loss: 2.646979570388794, Discriminator Loss: 34.41264343261719, Time: 2.0159895420074463 s\n",
      "Epoch: 3, Generator Loss: 5.318976879119873, Discriminator Loss: 18.642471313476562, Time: 1.9747190475463867 s\n",
      "Epoch: 4, Generator Loss: 1.44089937210083, Discriminator Loss: 13.051980018615723, Time: 2.017547369003296 s\n",
      "Epoch: 5, Generator Loss: 0.8607137799263, Discriminator Loss: 22.026199340820312, Time: 2.021512031555176 s\n",
      "Epoch: 6, Generator Loss: 0.12425529211759567, Discriminator Loss: 12.074004173278809, Time: 2.0257363319396973 s\n",
      "Epoch: 7, Generator Loss: 0.06516237556934357, Discriminator Loss: 8.879050254821777, Time: 2.012329578399658 s\n",
      "Epoch: 8, Generator Loss: 0.039519667625427246, Discriminator Loss: 8.351092338562012, Time: 2.014248847961426 s\n",
      "Epoch: 9, Generator Loss: 0.03110307827591896, Discriminator Loss: 8.768353462219238, Time: 2.0144546031951904 s\n",
      "Epoch: 10, Generator Loss: 0.02821732871234417, Discriminator Loss: 7.529183864593506, Time: 2.017503023147583 s\n",
      "Epoch: 11, Generator Loss: 0.015626905485987663, Discriminator Loss: 9.398796081542969, Time: 2.013737678527832 s\n",
      "Epoch: 12, Generator Loss: 0.017290547490119934, Discriminator Loss: 7.93740701675415, Time: 2.0127673149108887 s\n",
      "Epoch: 13, Generator Loss: 0.022780928760766983, Discriminator Loss: 7.791439056396484, Time: 2.0217175483703613 s\n",
      "Epoch: 14, Generator Loss: 0.02916981279850006, Discriminator Loss: 7.512073516845703, Time: 2.0216174125671387 s\n",
      "Epoch: 15, Generator Loss: 0.014894501306116581, Discriminator Loss: 7.202253818511963, Time: 2.027228593826294 s\n",
      "Epoch: 16, Generator Loss: 0.7250983715057373, Discriminator Loss: 12.713753700256348, Time: 2.0151169300079346 s\n",
      "Epoch: 17, Generator Loss: 4.264843940734863, Discriminator Loss: 5.105288505554199, Time: 2.025744915008545 s\n",
      "Epoch: 18, Generator Loss: 1.9036321640014648, Discriminator Loss: 3.4229395389556885, Time: 2.031662940979004 s\n",
      "Epoch: 19, Generator Loss: 0.5278568267822266, Discriminator Loss: 3.0226552486419678, Time: 2.030560255050659 s\n",
      "Epoch: 20, Generator Loss: 0.31921249628067017, Discriminator Loss: 3.6449689865112305, Time: 2.0413401126861572 s\n",
      "Epoch: 21, Generator Loss: 0.32210949063301086, Discriminator Loss: 6.534268856048584, Time: 2.0206096172332764 s\n",
      "Epoch: 22, Generator Loss: 0.23254184424877167, Discriminator Loss: 7.4608635902404785, Time: 2.02089262008667 s\n",
      "Epoch: 23, Generator Loss: 0.6048847436904907, Discriminator Loss: 3.8144595623016357, Time: 2.0207624435424805 s\n",
      "Epoch: 24, Generator Loss: 0.27258506417274475, Discriminator Loss: 3.9376420974731445, Time: 2.026876926422119 s\n",
      "Epoch: 25, Generator Loss: 0.2723231613636017, Discriminator Loss: 3.7718474864959717, Time: 2.021711826324463 s\n",
      "Epoch: 26, Generator Loss: 0.2300543338060379, Discriminator Loss: 3.9152884483337402, Time: 2.0211591720581055 s\n",
      "Epoch: 27, Generator Loss: 0.22458302974700928, Discriminator Loss: 3.837756872177124, Time: 2.0209968090057373 s\n",
      "Epoch: 28, Generator Loss: 0.10680974274873734, Discriminator Loss: 4.478097438812256, Time: 2.0261118412017822 s\n",
      "Epoch: 29, Generator Loss: 0.09905475378036499, Discriminator Loss: 4.28669548034668, Time: 2.0213193893432617 s\n",
      "Epoch: 30, Generator Loss: 0.07763181626796722, Discriminator Loss: 4.325791358947754, Time: 2.0220351219177246 s\n",
      "Epoch: 31, Generator Loss: 0.08085840940475464, Discriminator Loss: 4.572796821594238, Time: 2.021401882171631 s\n",
      "Epoch: 32, Generator Loss: 0.0640452429652214, Discriminator Loss: 4.503810405731201, Time: 2.0218966007232666 s\n",
      "Epoch: 33, Generator Loss: 0.07657092809677124, Discriminator Loss: 4.8635382652282715, Time: 2.0255625247955322 s\n",
      "Epoch: 34, Generator Loss: 0.06036998704075813, Discriminator Loss: 4.656764030456543, Time: 2.0254104137420654 s\n",
      "Epoch: 35, Generator Loss: 0.06783945858478546, Discriminator Loss: 4.7229905128479, Time: 2.025578260421753 s\n",
      "Epoch: 36, Generator Loss: 0.06927120685577393, Discriminator Loss: 4.577082633972168, Time: 2.0258054733276367 s\n",
      "Epoch: 37, Generator Loss: 0.08334110677242279, Discriminator Loss: 4.771244049072266, Time: 2.0256505012512207 s\n",
      "Epoch: 38, Generator Loss: 0.09721098095178604, Discriminator Loss: 4.975058078765869, Time: 2.026671886444092 s\n",
      "Epoch: 39, Generator Loss: 0.060991983860731125, Discriminator Loss: 5.601503372192383, Time: 2.0246260166168213 s\n",
      "Epoch: 40, Generator Loss: 0.04928666353225708, Discriminator Loss: 5.98392391204834, Time: 2.0259976387023926 s\n",
      "Epoch: 41, Generator Loss: 0.1022207960486412, Discriminator Loss: 5.362099647521973, Time: 2.0218868255615234 s\n",
      "Epoch: 42, Generator Loss: 0.047308433800935745, Discriminator Loss: 6.166211128234863, Time: 2.025158405303955 s\n",
      "Epoch: 43, Generator Loss: 0.03053874708712101, Discriminator Loss: 5.957358360290527, Time: 2.024277448654175 s\n",
      "Epoch: 44, Generator Loss: 0.026468107476830482, Discriminator Loss: 6.237633228302002, Time: 2.027496814727783 s\n",
      "Epoch: 45, Generator Loss: 0.014083495363593102, Discriminator Loss: 6.005031108856201, Time: 2.0256404876708984 s\n",
      "Epoch: 46, Generator Loss: 0.01488210167735815, Discriminator Loss: 6.189688682556152, Time: 2.024709701538086 s\n",
      "Epoch: 47, Generator Loss: 0.025348125025629997, Discriminator Loss: 5.837159156799316, Time: 2.0521578788757324 s\n",
      "Epoch: 48, Generator Loss: 0.06382787972688675, Discriminator Loss: 5.3945698738098145, Time: 2.044769763946533 s\n",
      "Epoch: 49, Generator Loss: 0.03258947283029556, Discriminator Loss: 8.459773063659668, Time: 2.0366153717041016 s\n",
      "Epoch: 50, Generator Loss: 0.029798539355397224, Discriminator Loss: 7.22152853012085, Time: 2.0338616371154785 s\n",
      "Epoch: 51, Generator Loss: 0.02349168434739113, Discriminator Loss: 6.582276344299316, Time: 2.0317482948303223 s\n",
      "Epoch: 52, Generator Loss: 0.03261840343475342, Discriminator Loss: 6.947439193725586, Time: 2.0351200103759766 s\n",
      "Epoch: 53, Generator Loss: 0.04040152207016945, Discriminator Loss: 8.717089653015137, Time: 2.0309293270111084 s\n",
      "Epoch: 54, Generator Loss: 0.010942235589027405, Discriminator Loss: 7.572903156280518, Time: 2.0258736610412598 s\n",
      "Epoch: 55, Generator Loss: 0.021929102018475533, Discriminator Loss: 6.298430442810059, Time: 2.0260701179504395 s\n",
      "Epoch: 56, Generator Loss: 0.018612664192914963, Discriminator Loss: 5.968009948730469, Time: 2.0243983268737793 s\n",
      "Epoch: 57, Generator Loss: 0.03156086057424545, Discriminator Loss: 6.164643287658691, Time: 2.0656075477600098 s\n",
      "Epoch: 58, Generator Loss: 0.02295595221221447, Discriminator Loss: 6.235112190246582, Time: 2.109941005706787 s\n",
      "Epoch: 59, Generator Loss: 0.016073571518063545, Discriminator Loss: 7.1840691566467285, Time: 2.0429396629333496 s\n",
      "Epoch: 60, Generator Loss: 0.016834085807204247, Discriminator Loss: 6.5186004638671875, Time: 2.044771671295166 s\n",
      "Epoch: 61, Generator Loss: 0.018170379102230072, Discriminator Loss: 6.588496208190918, Time: 2.0434868335723877 s\n",
      "Epoch: 62, Generator Loss: 0.0202887374907732, Discriminator Loss: 6.66885232925415, Time: 2.04050874710083 s\n",
      "Epoch: 63, Generator Loss: 0.021811693906784058, Discriminator Loss: 6.398632049560547, Time: 2.0402801036834717 s\n",
      "Epoch: 64, Generator Loss: 0.038417719304561615, Discriminator Loss: 5.517795562744141, Time: 2.040879726409912 s\n",
      "Epoch: 65, Generator Loss: 0.029627347365021706, Discriminator Loss: 6.426751136779785, Time: 2.0387327671051025 s\n",
      "Epoch: 66, Generator Loss: 0.04224691912531853, Discriminator Loss: 6.220682144165039, Time: 2.050922393798828 s\n",
      "Epoch: 67, Generator Loss: 0.03555126115679741, Discriminator Loss: 6.454245090484619, Time: 2.040489673614502 s\n",
      "Epoch: 68, Generator Loss: 0.024688387289643288, Discriminator Loss: 6.467562675476074, Time: 2.039672374725342 s\n",
      "Epoch: 69, Generator Loss: 0.03291134536266327, Discriminator Loss: 6.010753631591797, Time: 2.040428400039673 s\n",
      "Epoch: 70, Generator Loss: 0.05853904411196709, Discriminator Loss: 6.109947681427002, Time: 2.0406241416931152 s\n",
      "Epoch: 71, Generator Loss: 0.03276943415403366, Discriminator Loss: 6.515541076660156, Time: 2.0399489402770996 s\n",
      "Epoch: 72, Generator Loss: 0.043111830949783325, Discriminator Loss: 6.116955280303955, Time: 2.0416312217712402 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73, Generator Loss: 0.3677635192871094, Discriminator Loss: 6.492313385009766, Time: 2.039234161376953 s\n",
      "Epoch: 74, Generator Loss: 0.3330622911453247, Discriminator Loss: 6.9561309814453125, Time: 2.074063777923584 s\n",
      "Epoch: 75, Generator Loss: 0.4410649836063385, Discriminator Loss: 7.362417697906494, Time: 2.0963199138641357 s\n",
      "Epoch: 76, Generator Loss: 0.2722685933113098, Discriminator Loss: 8.133783340454102, Time: 2.1024973392486572 s\n",
      "Epoch: 77, Generator Loss: 0.33950573205947876, Discriminator Loss: 17.286474227905273, Time: 2.0872318744659424 s\n",
      "Epoch: 78, Generator Loss: 2.8831565380096436, Discriminator Loss: 19.125118255615234, Time: 2.040855884552002 s\n",
      "Epoch: 79, Generator Loss: 0.29605889320373535, Discriminator Loss: 14.853711128234863, Time: 2.0350003242492676 s\n",
      "Epoch: 80, Generator Loss: 0.3202453851699829, Discriminator Loss: 16.538509368896484, Time: 1.997535228729248 s\n",
      "Epoch: 81, Generator Loss: 1.3176625967025757, Discriminator Loss: 25.081369400024414, Time: 2.0342860221862793 s\n",
      "Epoch: 82, Generator Loss: 2.0049095153808594, Discriminator Loss: 10.635418891906738, Time: 2.0352485179901123 s\n",
      "Epoch: 83, Generator Loss: 0.3203420639038086, Discriminator Loss: 11.607595443725586, Time: 2.036208152770996 s\n",
      "Epoch: 84, Generator Loss: 0.3742431104183197, Discriminator Loss: 8.551619529724121, Time: 2.03590726852417 s\n",
      "Epoch: 85, Generator Loss: 0.2396799921989441, Discriminator Loss: 10.691490173339844, Time: 2.0393168926239014 s\n",
      "Epoch: 86, Generator Loss: 0.031348735094070435, Discriminator Loss: 13.752579689025879, Time: 2.0352063179016113 s\n",
      "Epoch: 87, Generator Loss: 0.04428501054644585, Discriminator Loss: 9.242566108703613, Time: 2.0342154502868652 s\n",
      "Epoch: 88, Generator Loss: 0.06988312304019928, Discriminator Loss: 7.4967827796936035, Time: 2.0352282524108887 s\n",
      "Epoch: 89, Generator Loss: 0.02946186624467373, Discriminator Loss: 8.764165878295898, Time: 2.035172939300537 s\n",
      "Epoch: 90, Generator Loss: 0.06311491876840591, Discriminator Loss: 9.276054382324219, Time: 2.035874366760254 s\n",
      "Epoch: 91, Generator Loss: 0.06159546598792076, Discriminator Loss: 10.804998397827148, Time: 2.034813642501831 s\n",
      "Epoch: 92, Generator Loss: 0.02591627836227417, Discriminator Loss: 9.460140228271484, Time: 2.036445379257202 s\n",
      "Epoch: 93, Generator Loss: 0.014029841870069504, Discriminator Loss: 9.653564453125, Time: 2.034451484680176 s\n",
      "Epoch: 94, Generator Loss: 0.017313683405518532, Discriminator Loss: 9.238036155700684, Time: 2.0400214195251465 s\n",
      "Epoch: 95, Generator Loss: 0.017972003668546677, Discriminator Loss: 8.644872665405273, Time: 2.0347774028778076 s\n",
      "Epoch: 96, Generator Loss: 0.009982270188629627, Discriminator Loss: 8.688608169555664, Time: 2.0366008281707764 s\n",
      "Epoch: 97, Generator Loss: 0.013941737823188305, Discriminator Loss: 8.833096504211426, Time: 2.034365653991699 s\n",
      "Epoch: 98, Generator Loss: 0.011740518733859062, Discriminator Loss: 8.538369178771973, Time: 2.040408134460449 s\n",
      "Epoch: 99, Generator Loss: 0.014693628996610641, Discriminator Loss: 9.239105224609375, Time: 2.0276877880096436 s\n",
      "Epoch: 100, Generator Loss: 0.004784048534929752, Discriminator Loss: 9.22630786895752, Time: 2.017523765563965 s\n",
      "Epoch: 101, Generator Loss: 0.014418989419937134, Discriminator Loss: 8.804433822631836, Time: 2.034852981567383 s\n",
      "Epoch: 102, Generator Loss: 0.017567401751875877, Discriminator Loss: 9.002306938171387, Time: 2.0492966175079346 s\n",
      "Epoch: 103, Generator Loss: 0.007752552628517151, Discriminator Loss: 8.976527214050293, Time: 2.0415380001068115 s\n",
      "Epoch: 104, Generator Loss: 0.012815553694963455, Discriminator Loss: 7.6105170249938965, Time: 2.0298314094543457 s\n",
      "Epoch: 105, Generator Loss: 0.011289880611002445, Discriminator Loss: 7.9100117683410645, Time: 2.0402274131774902 s\n",
      "Epoch: 106, Generator Loss: 0.013358467258512974, Discriminator Loss: 8.146629333496094, Time: 2.0394606590270996 s\n",
      "Epoch: 107, Generator Loss: 0.01657712459564209, Discriminator Loss: 9.291947364807129, Time: 2.035728693008423 s\n",
      "Epoch: 108, Generator Loss: 0.005705809686332941, Discriminator Loss: 8.366682052612305, Time: 2.035146951675415 s\n",
      "Epoch: 109, Generator Loss: 0.02401149831712246, Discriminator Loss: 8.497550964355469, Time: 2.039804697036743 s\n",
      "Epoch: 110, Generator Loss: 0.012803858146071434, Discriminator Loss: 9.03153133392334, Time: 2.02725887298584 s\n",
      "Epoch: 111, Generator Loss: 0.02710547484457493, Discriminator Loss: 8.881858825683594, Time: 2.034414291381836 s\n",
      "Epoch: 112, Generator Loss: 0.010287923738360405, Discriminator Loss: 10.002764701843262, Time: 2.0285513401031494 s\n",
      "Epoch: 113, Generator Loss: 0.009748312644660473, Discriminator Loss: 8.825758934020996, Time: 2.0307791233062744 s\n",
      "Epoch: 114, Generator Loss: 0.0432363860309124, Discriminator Loss: 11.063623428344727, Time: 2.0325732231140137 s\n",
      "Epoch: 115, Generator Loss: 0.04636583477258682, Discriminator Loss: 9.576358795166016, Time: 2.0263214111328125 s\n",
      "Epoch: 116, Generator Loss: 0.014640477485954762, Discriminator Loss: 11.184274673461914, Time: 2.025588274002075 s\n",
      "Epoch: 117, Generator Loss: 0.006793296430259943, Discriminator Loss: 10.135725975036621, Time: 2.025604724884033 s\n",
      "Epoch: 118, Generator Loss: 0.010764812119305134, Discriminator Loss: 9.875988960266113, Time: 2.037207841873169 s\n",
      "Epoch: 119, Generator Loss: 0.02120787464082241, Discriminator Loss: 7.7535929679870605, Time: 2.0361032485961914 s\n",
      "Epoch: 120, Generator Loss: 0.020201649516820908, Discriminator Loss: 7.634909152984619, Time: 2.039558172225952 s\n",
      "Epoch: 121, Generator Loss: 0.020110705867409706, Discriminator Loss: 7.087742805480957, Time: 2.0358312129974365 s\n",
      "Epoch: 122, Generator Loss: 0.027407214045524597, Discriminator Loss: 7.716139316558838, Time: 2.0395190715789795 s\n",
      "Epoch: 123, Generator Loss: 0.02234257012605667, Discriminator Loss: 7.0473198890686035, Time: 2.035759449005127 s\n",
      "Epoch: 124, Generator Loss: 0.028692131862044334, Discriminator Loss: 6.826152801513672, Time: 2.040907621383667 s\n",
      "Epoch: 125, Generator Loss: 0.022817974910140038, Discriminator Loss: 6.959852695465088, Time: 2.0340681076049805 s\n",
      "Epoch: 126, Generator Loss: 0.018458573147654533, Discriminator Loss: 6.954340934753418, Time: 2.036432981491089 s\n",
      "Epoch: 127, Generator Loss: 0.019296279177069664, Discriminator Loss: 7.242702960968018, Time: 2.0339999198913574 s\n",
      "Epoch: 128, Generator Loss: 0.027575410902500153, Discriminator Loss: 7.411195278167725, Time: 2.04071307182312 s\n",
      "Epoch: 129, Generator Loss: 0.04822617769241333, Discriminator Loss: 7.15481424331665, Time: 2.0392913818359375 s\n",
      "Epoch: 130, Generator Loss: 0.03709173575043678, Discriminator Loss: 6.674892425537109, Time: 2.0413713455200195 s\n",
      "Epoch: 131, Generator Loss: 0.027573293074965477, Discriminator Loss: 7.028357982635498, Time: 2.039346218109131 s\n",
      "Epoch: 132, Generator Loss: 0.032052453607320786, Discriminator Loss: 7.513993740081787, Time: 2.0244061946868896 s\n",
      "Epoch: 133, Generator Loss: 0.04505341127514839, Discriminator Loss: 6.758478164672852, Time: 2.036266803741455 s\n",
      "Epoch: 134, Generator Loss: 0.24733972549438477, Discriminator Loss: 9.236197471618652, Time: 2.039989948272705 s\n",
      "Epoch: 135, Generator Loss: 1.5391045808792114, Discriminator Loss: 12.359237670898438, Time: 2.0403401851654053 s\n",
      "Epoch: 136, Generator Loss: 3.846531629562378, Discriminator Loss: 22.179773330688477, Time: 2.039776086807251 s\n",
      "Epoch: 137, Generator Loss: 3.203943967819214, Discriminator Loss: 13.983970642089844, Time: 2.0353760719299316 s\n",
      "Epoch: 138, Generator Loss: 0.599910318851471, Discriminator Loss: 25.438013076782227, Time: 2.036034107208252 s\n",
      "Epoch: 139, Generator Loss: 0.2677280902862549, Discriminator Loss: 28.629348754882812, Time: 2.0089871883392334 s\n",
      "Epoch: 140, Generator Loss: 0.12065769731998444, Discriminator Loss: 19.319427490234375, Time: 2.1859138011932373 s\n",
      "Epoch: 141, Generator Loss: 1.1862481832504272, Discriminator Loss: 18.679454803466797, Time: 2.079150915145874 s\n",
      "Epoch: 142, Generator Loss: 0.23982469737529755, Discriminator Loss: 18.28238296508789, Time: 2.105759382247925 s\n",
      "Epoch: 143, Generator Loss: 0.07351849973201752, Discriminator Loss: 20.9566707611084, Time: 2.0856173038482666 s\n",
      "Epoch: 144, Generator Loss: 0.07766696810722351, Discriminator Loss: 18.892900466918945, Time: 2.0891196727752686 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 145, Generator Loss: 0.05460716038942337, Discriminator Loss: 15.451957702636719, Time: 2.1000101566314697 s\n",
      "Epoch: 146, Generator Loss: 0.02600259706377983, Discriminator Loss: 14.705052375793457, Time: 2.0951082706451416 s\n",
      "Epoch: 147, Generator Loss: 0.017832079902291298, Discriminator Loss: 12.606193542480469, Time: 2.064513921737671 s\n",
      "Epoch: 148, Generator Loss: 0.017644619569182396, Discriminator Loss: 13.217999458312988, Time: 2.1346592903137207 s\n",
      "Epoch: 149, Generator Loss: 0.03499430790543556, Discriminator Loss: 12.196820259094238, Time: 2.1821746826171875 s\n",
      "Epoch: 150, Generator Loss: 0.011725581251084805, Discriminator Loss: 12.507603645324707, Time: 2.1273679733276367 s\n",
      "Epoch: 151, Generator Loss: 0.007529640570282936, Discriminator Loss: 11.802114486694336, Time: 2.0848770141601562 s\n",
      "Epoch: 152, Generator Loss: 0.004677344113588333, Discriminator Loss: 12.352686882019043, Time: 2.113619804382324 s\n",
      "Epoch: 153, Generator Loss: 0.00577980000525713, Discriminator Loss: 10.638768196105957, Time: 2.1655163764953613 s\n",
      "Epoch: 154, Generator Loss: 0.020651856437325478, Discriminator Loss: 10.893048286437988, Time: 2.069032907485962 s\n",
      "Epoch: 155, Generator Loss: 0.040719568729400635, Discriminator Loss: 13.970542907714844, Time: 2.062458038330078 s\n",
      "Epoch: 156, Generator Loss: 0.024310674518346786, Discriminator Loss: 11.984587669372559, Time: 2.068241834640503 s\n",
      "Epoch: 157, Generator Loss: 0.00821960810571909, Discriminator Loss: 11.553924560546875, Time: 2.0430150032043457 s\n",
      "Epoch: 158, Generator Loss: 0.029180489480495453, Discriminator Loss: 11.443244934082031, Time: 2.0662333965301514 s\n",
      "Epoch: 159, Generator Loss: 0.02422918938100338, Discriminator Loss: 11.814913749694824, Time: 2.081664562225342 s\n",
      "Epoch: 160, Generator Loss: 0.008389418013393879, Discriminator Loss: 12.190391540527344, Time: 2.05340313911438 s\n",
      "Epoch: 161, Generator Loss: 0.006329639349132776, Discriminator Loss: 11.874114036560059, Time: 2.1093382835388184 s\n",
      "Epoch: 162, Generator Loss: 0.02241237834095955, Discriminator Loss: 9.739492416381836, Time: 2.0527825355529785 s\n",
      "Epoch: 163, Generator Loss: 0.014416344463825226, Discriminator Loss: 11.12745189666748, Time: 2.0508158206939697 s\n",
      "Epoch: 164, Generator Loss: 0.018195655196905136, Discriminator Loss: 9.7265043258667, Time: 2.155362367630005 s\n",
      "Epoch: 165, Generator Loss: 0.0257070604711771, Discriminator Loss: 10.144194602966309, Time: 2.040717601776123 s\n",
      "Epoch: 166, Generator Loss: 0.01778068207204342, Discriminator Loss: 10.156669616699219, Time: 2.173827648162842 s\n",
      "Epoch: 167, Generator Loss: 0.017619896680116653, Discriminator Loss: 9.074699401855469, Time: 2.046264171600342 s\n",
      "Epoch: 168, Generator Loss: 0.013232501223683357, Discriminator Loss: 8.276388168334961, Time: 2.1033108234405518 s\n",
      "Epoch: 169, Generator Loss: 0.02195189893245697, Discriminator Loss: 8.836888313293457, Time: 2.048252582550049 s\n",
      "Epoch: 170, Generator Loss: 0.01850070059299469, Discriminator Loss: 9.67090892791748, Time: 2.0663020610809326 s\n",
      "Epoch: 171, Generator Loss: 0.011208126321434975, Discriminator Loss: 8.704533576965332, Time: 2.1004414558410645 s\n",
      "Epoch: 172, Generator Loss: 0.022359684109687805, Discriminator Loss: 9.20626163482666, Time: 2.0370664596557617 s\n",
      "Epoch: 173, Generator Loss: 0.01643664389848709, Discriminator Loss: 8.91565227508545, Time: 2.179415702819824 s\n",
      "Epoch: 174, Generator Loss: 0.018522128462791443, Discriminator Loss: 9.742505073547363, Time: 2.1585614681243896 s\n",
      "Epoch: 175, Generator Loss: 0.017536921426653862, Discriminator Loss: 8.585211753845215, Time: 2.204524278640747 s\n",
      "Epoch: 176, Generator Loss: 0.010656801052391529, Discriminator Loss: 10.173779487609863, Time: 2.044904947280884 s\n",
      "Epoch: 177, Generator Loss: 0.0475059375166893, Discriminator Loss: 12.279609680175781, Time: 2.027204751968384 s\n",
      "Epoch: 178, Generator Loss: 0.020790472626686096, Discriminator Loss: 11.123048782348633, Time: 2.1304221153259277 s\n",
      "Epoch: 179, Generator Loss: 0.02200053259730339, Discriminator Loss: 13.769721984863281, Time: 2.060638427734375 s\n",
      "Epoch: 180, Generator Loss: 0.00821730401366949, Discriminator Loss: 12.650557518005371, Time: 2.0702109336853027 s\n",
      "Epoch: 181, Generator Loss: 0.06887463480234146, Discriminator Loss: 18.026500701904297, Time: 2.0907344818115234 s\n",
      "Epoch: 182, Generator Loss: 0.09516157954931259, Discriminator Loss: 15.539685249328613, Time: 2.040269613265991 s\n",
      "Epoch: 183, Generator Loss: 0.02206595242023468, Discriminator Loss: 13.781783103942871, Time: 2.0921876430511475 s\n",
      "Epoch: 184, Generator Loss: 0.004091721028089523, Discriminator Loss: 12.6108980178833, Time: 2.146383047103882 s\n",
      "Epoch: 185, Generator Loss: 0.004205453675240278, Discriminator Loss: 11.867128372192383, Time: 2.058257818222046 s\n",
      "Epoch: 186, Generator Loss: 0.08042249083518982, Discriminator Loss: 13.566608428955078, Time: 2.1490397453308105 s\n",
      "Epoch: 187, Generator Loss: 0.16926634311676025, Discriminator Loss: 22.777545928955078, Time: 2.1113662719726562 s\n",
      "Epoch: 188, Generator Loss: 0.009364122524857521, Discriminator Loss: 20.86256980895996, Time: 2.103454351425171 s\n",
      "Epoch: 189, Generator Loss: 0.0066758026368916035, Discriminator Loss: 16.64238929748535, Time: 2.112031936645508 s\n",
      "Epoch: 190, Generator Loss: 0.010128793306648731, Discriminator Loss: 11.696999549865723, Time: 2.1948928833007812 s\n",
      "Epoch: 191, Generator Loss: 0.00937006063759327, Discriminator Loss: 11.100778579711914, Time: 2.187701463699341 s\n",
      "Epoch: 192, Generator Loss: 0.009546136483550072, Discriminator Loss: 11.29211139678955, Time: 2.009570837020874 s\n",
      "Epoch: 193, Generator Loss: 0.03185144066810608, Discriminator Loss: 12.118705749511719, Time: 2.1473143100738525 s\n",
      "Epoch: 194, Generator Loss: 0.006905238144099712, Discriminator Loss: 14.898399353027344, Time: 2.165342330932617 s\n",
      "Epoch: 195, Generator Loss: 0.00712826382368803, Discriminator Loss: 15.08376407623291, Time: 2.06315541267395 s\n",
      "Epoch: 196, Generator Loss: 0.004548828583210707, Discriminator Loss: 10.008971214294434, Time: 2.1560018062591553 s\n",
      "Epoch: 197, Generator Loss: 0.01500913966447115, Discriminator Loss: 9.356051445007324, Time: 2.1597461700439453 s\n",
      "Epoch: 198, Generator Loss: 0.008132606744766235, Discriminator Loss: 9.929473876953125, Time: 2.0736019611358643 s\n",
      "Epoch: 199, Generator Loss: 0.014248721301555634, Discriminator Loss: 9.120490074157715, Time: 2.18424654006958 s\n"
     ]
    }
   ],
   "source": [
    "# create a seed to visualize the progress\n",
    "num_examples_to_generate = 16\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "\n",
    "patience = 0\n",
    "print(\"starting training\")\n",
    "for epoch in range(epochs):\n",
    "    time_start = time.time()\n",
    "\n",
    "    batches = 0\n",
    "    for images, _ in train_gen:\n",
    "        train_step(images)\n",
    "        batches += 1\n",
    "        if batches >= train_size / batch_size:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break\n",
    "\n",
    "    time_finish = time.time()\n",
    "    end_time = (time_finish-time_start)\n",
    "\n",
    "    if (epoch % log_freq == 0):\n",
    "\n",
    "        print ('Epoch: {}, Generator Loss: {}, Discriminator Loss: {}, Time: {} s'.format(\n",
    "               epoch,\n",
    "               generator_loss.result(),\n",
    "               discriminator_loss.result(),\n",
    "               end_time))\n",
    "\n",
    "        if ((generator_loss.result() < min_loss) or (discriminator_loss.result() < min_loss)):    \n",
    "            if not os.path.exists(models_directory):\n",
    "                os.makedirs(models_directory)\n",
    "            # serialize weights to HDF5\n",
    "            generator.save_weights(models_directory + \"best{}-generator.h5\".format(identifier))\n",
    "            discriminator.save_weights(models_directory + \"best{}-discriminator.h5\".format(identifier))\n",
    "            min_loss = min(generator_loss.result(), discriminator_loss.result())\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "\n",
    "        generated_image = generator(seed, training=False)\n",
    "        with train_summary_writer.as_default():\n",
    "            tf.summary.image('generated_image', generated_image, step=epoch)\n",
    "            tf.summary.scalar('generator_loss', generator_loss.result(), step=epoch)\n",
    "            tf.summary.scalar('discriminator_loss', discriminator_loss.result(), step=epoch)\n",
    "            generator_loss.reset_states()           \n",
    "            discriminator_loss.reset_states()           \n",
    "\n",
    "    if patience >= max_patience:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
